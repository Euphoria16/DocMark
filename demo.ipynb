{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InternLM2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ğŸ‘‰v4.50ğŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "[INFO:swift] Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup and Model Loading\n",
    "import torch\n",
    "from swift.utils import seed_everything\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "from utils import load_image\n",
    "\n",
    "model_path = 'HanXiao1999/DocMark-2B'\n",
    "model = AutoModel.from_pretrained(\n",
    "model_path,\n",
    "torch_dtype=torch.bfloat16,\n",
    "low_cpu_mem_usage=True,\n",
    "use_flash_attn=True,\n",
    "trust_remote_code=True).eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=True, legacy=False, add_prefix_space=False)\n",
    "generation_config = dict(max_new_tokens=2048, do_sample=False)\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <txt>nutmegstate FEDERAL CREDIT UNION</txt>\n",
      "Answer: <txt_gd><ref>nutmegstate</ref><quad>(334,104),(910,88),(912,200),(336,216)</quad><ref>FEDERAL CREDIT UNION</ref><quad>(336,228),(910,212),(911,252),(337,268)</quad><ref>nultmegstate</ref><quad>(212,524),(378,524),(378,552),(212,552)</quad> </txt_gd>\n"
     ]
    }
   ],
   "source": [
    "# Load and process text-rich natural image\n",
    "# Extract text from the image\n",
    "image_path = 'examples/text_img.jpg'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>Could you extract the text from the image for me?'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)\n",
    "# OCR with grounding\n",
    "question = '<image>OCR with grounding:'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <md>---\n",
      "\n",
      "Citizens' Commission on Science, Law and the Food Supply\n",
      "\n",
      "Kindly have check drawn to order of\n",
      "\n",
      "CHANNING H. LUSHBOUGH\n",
      "\n",
      "to cover: REFUND OF PERSONAL LOAN AGAINST TRAVEL EXPENSES INCURRED BY DR. CRAMPTON\n",
      "\n",
      "SEE VOUCHER #33 AND RECEIPT ATTACHED\n",
      "\n",
      "Charge to\n",
      "MEETINGS $100.00\n",
      "\n",
      "APPROVED FOR PAYMENT\n",
      "\n",
      "By C. X. Lushbough\n",
      "\n",
      "---\n",
      "\n",
      "Source: https://www.industrydocuments.ucsf.edu/docs/ljim0227</md>\n"
     ]
    }
   ],
   "source": [
    "# Document Processing\n",
    "# Convert document images into structured markup formats\n",
    "image_path = 'examples/example_doc.png'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>How can I convert this document into a structured markup language format?'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <latex>é«˜æ•°å¿…ç»ƒ 1000 é¢˜ç­”æ¡ˆè§£æç”± (I) çŸ¥, å½“ $n \\rightarrow \\infty$ æ—¶, $x_{n} \\rightarrow 0$, æ•…$\\lim _{n \\rightarrow \\infty}\\left(\\frac{x_{n+1}}{x_{n}}\\right)^{\\frac{1}{x_{n}}}=\\lim _{n \\rightarrow \\infty}\\left(\\frac{\\sin x_{n}}{x_{n}}\\right)^{\\frac{1}{x_{n}}}=\\lim _{n \\rightarrow \\infty}\\left(\\frac{\\sin t}{t}\\right)^{\\frac{1}{t}}= e ^{-\\frac{1}{t}}.$156.ã€è¯æ˜ã€‘å› $x_{n+1}=\\sqrt{x_{n}\\left(3-x_{n}\\right)} \\leqslant \\sqrt{\\left(\\frac{x_{n}+3-x_{n}}{2}\\right)^{\\frac{2}{2}}}=\\frac{3}{2}, n=1,2, \\cdots$æ•… $\\left\\{x_{n}\\right\\}$ æœ‰ä¸Šç•Œ.åˆ $x_{n+1} \\geqslant 0, x_{n+1}^{2}-x_{n}^{2}=x_{n}\\left(3-x_{n}\\right)-x_{n}^{2}=x_{n}\\left(3-2 x_{n}\\right) \\geqslant 0$, æ•… $x_{n+1} \\geqslant x_{n}, n=$$2,3, \\cdots$, ä»è€Œ $n>1$ æ—¶, $\\left\\{x_{n}\\right\\}$ ä¸ºå•è°ƒé€’å¢æ•°åˆ—.ç”±å•è°ƒæœ‰ç•ŒåŸç†çŸ¥, $\\lim _{n \\rightarrow \\infty} x_{n}$ å­˜åœ¨, ä¸å¦¨è®¾ $A=\\lim _{n \\rightarrow \\infty} x_{n}$, ç”± $\\lim _{n \\rightarrow \\infty} x_{n+1}=\\lim _{n \\rightarrow \\infty}$$\\sqrt{x_{n}\\left(3-x_{n}\\right)}$, å¾— $A=\\sqrt{A(3-A)}$, å³ $2 A^{2}=3 A$, å¾— $A=\\frac{3}{2}$ æˆ– $A=0$, å› æ•°åˆ— $\\left\\{x_{n}\\right\\}$ ä¸ºå•è°ƒé€’å¢æ•°åˆ—, ä¸” $x_{1}>0$, æ•… $A>0, \\lim _{n \\rightarrow \\infty} x_{n}=\\frac{3}{2}$.157.ã€è§£æã€‘å›  $x_{1}=10, x_{n+1}=\\sqrt{6+x_{n}}$, æ•… $x_{2}=\\sqrt{6+10}=4, x_{2}<x_{1}$, å‡è®¾ $x_{n}<$$x_{n-1}$, åˆ™ $x_{n+1}=\\sqrt{6+x_{n}}<\\sqrt{6+x_{n-1}}=x_{n}$, æ•…æ•°åˆ— $\\left\\{x_{n}\\right\\}$ å•è°ƒé€’å‡.åˆ $x_{n+1}=\\sqrt{6+x_{n}} \\geqslant 0$, æ•… 0 ä¸ºæ•°åˆ— $\\left\\{x_{n}\\right\\}$ çš„ä¸‹ç•Œ, ä»è€Œç”±å•è°ƒæœ‰ç•ŒåŸç†çŸ¥,$\\left\\{x_{n}\\right\\}$ çš„æé™å­˜åœ¨, è®¾ $\\lim _{n \\rightarrow \\infty} x_{n}=A$, åˆ™åœ¨ç­‰å¼ $x_{n+1}=\\sqrt{6+x_{n}}$ çš„ä¸¤ç«¯å–æé™, å¾—$\\lim _{n \\rightarrow \\infty} x_{n+1}=\\lim _{n \\rightarrow \\infty} \\sqrt{6+x_{n}} \\text {, å³ } A=\\sqrt{6+A} \\text {, }$è§£ä¹‹å¾—å”¯ä¸€è§£ $A=3$, æ•… $\\lim _{n \\rightarrow \\infty} x_{n}=3$.158.ã€è§£æã€‘$\\begin{aligned}\n",
      "\\lim _{n \\rightarrow \\infty} \\tan ^{n}\\left(\\frac{\\pi}{4}+\\frac{2}{n}\\right) & =\\lim _{n \\rightarrow \\infty}\\left[1+\\tan \\left(\\frac{\\pi}{4}+\\frac{2}{n}\\right)-1\\right]^{n} \\\\\n",
      "& =\\lim _{n \\rightarrow \\infty}\\left[1+\\tan \\left(\\frac{\\pi}{4}+\\frac{2}{n}\\right)-1\\right] \\tan \\left(\\frac{\\pi}{4+\\frac{2}{n}}\\right)-\\left[\\tan \\left(\\frac{\\pi}{4+\\frac{2}{n}}\\right)-1\\right]^{-n} \\\\\n",
      "& = e ^{\\lim _{n \\rightarrow \\infty} \\tan \\left(\\frac{\\pi}{4+\\frac{2}{n}}\\right)-1},\n",
      "\\end{aligned}$è½¬åŒ–æˆå‡½æ•°æé™$\\begin{aligned}\n",
      "\\lim _{x \\rightarrow+\\infty}\\left[\\tan \\left(\\frac{\\pi}{4}+\\frac{2}{x}\\right)-1\\right] & \\stackrel{\\text { ä»¤ } x=\\frac{1}{t}}{=} \\lim _{t \\rightarrow 0} \\frac{\\tan \\left(\\frac{\\pi}{4}+2 t\\right)-1}{t} \\\\\n",
      "& =\\lim _{t \\rightarrow 0^{+}} \\frac{\\sec ^{2}\\left(\\frac{\\pi}{4}+2 t\\right) \\cdot 2}{1}=4\n",
      "\\end{aligned}$42</latex>\n"
     ]
    }
   ],
   "source": [
    "# Document to LaTeX Conversion\n",
    "image_path = 'examples/latex_page.jpg'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>Convert the document into latex format:'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <html_brief>æ²å›­é›ªï¼Œæ²å›­é›ªæºäºéŸ©å›½ã€‚è¡¨è¾¾äº†æ—¶å°šã€å‰å«åŠæ½®æµä¸ªæ€§çš„éƒ½å¸‚ä¸€æ—ï¼›ä»¥è‡ªç”±ç»„åˆï¼Œæµªæ¼«ä¼‘é—²çš„è‰²å½©ï¼›è¿½æ±‚çº¦çº¦ã€æ—¶å°šçš„è®¾è®¡é£æ ¼ï¼›é«˜å“è´¨çš„é¢æ–™ï¼Œç²¾ç¾çš„å·¥è‰ºä½“ç°äº†â€œæ²å›­é›ªâ€ particular when ï¼›è®¾è®¡é£æ ¼ä»¥æ—¶å°šã€ç®€æ´ã€æ½®æµã€ä¸ªæ€§çš„è¡¨ç°å½¢å¼å®Œç¾åŒ…è£…éƒ½å¸‚å¥³æ€§ï¼Œå……åˆ†å½°æ˜¾ç°ä»£å¥³æ€§çš„é­…åŠ›å’Œè‡ªä¿¡ï¼Œç®€çº¦è®¾è®¡ï¼Œåˆ«è‡´çš„ç»†èŠ‚å˜åŒ–ï¼Œè€ƒç©¶çš„é¢æ–™ï¼Œç²¾å·§çš„å‰ªå‰ªåšå·¥ï¼Œæ›´é€‚åˆç°ä»£æ—¶å°šå¥³æ€§çš„è£…æ‰®éœ€æ±‚ã€‚\n",
      "æ²å›­é›ªå“ç‰Œå«ä¹‰\n",
      "æ²å›­é›ªå“ç‰Œåç§°æºäºç¾å›½è‘—åæ—¶å°šå®¶ï¼Œåšä¸ºæ—¶å°šæœè£…è®¾è®¡å¸ˆçš„æ²å›­é›ªåŒæ—¶å–œæ¬¢ç™»å±±ï¼Œä¸ºè‘—åçš„å†’é™©å®¶ã€ä½“ç°äº†éƒ½å¸‚å¥³æ€§åœ¨åŸå¸‚å’Œè‡ªç„¶ä¹‹é—´æ¸¸åˆƒæœ‰ä½™è¿½æ±‚ä¸ªäººè‡ªç”±ï¼Œå´‡å°šè‡ªç„¶çš„ç²¾ç¥ã€‚\n",
      "æ²å›­é›ªå…¬å¸ä»‹ç»\n",
      "ä¸œèæµ·è‡ªæœé¥°æœ‰é™å…¬å¸æ˜¯ä¸€å®¶é›†è®¾è®¡ã€å¼€å‘ã€ç”Ÿäº§ã€é”€å”®ä¸ºä¸€ä½“çš„å¥³è£…ä¼ä¸šï¼Œæ‹¥æœ‰è‡ªåˆ›â€œæ²å›­é›ªâ€æ—¶è£…å“ç‰Œã€‚åœ¨äº§å“ä¸Šï¼Œå…¬å¸æŠ•å…¥äº†ç›¸å½“å¤§çš„åŠ›åº¦ï¼Œæ‹›è˜ä¸€æ‰¹å…·æœ‰ä¸“ä¸šæŠ€æœ¯çš„äº§å“è®¾è®¡é˜Ÿä¼ï¼Œå¹¶ä»¥è®¾è®¡ä¸ºé¾™å¤´ï¼Œå…¨åŠ›æ‰“é€ å›½é™…çŸ¥åå¥³è£…å“ç‰Œä¸ºç›®æ ‡ã€‚\n",
      "å“ç‰Œä¼˜åŠ¿\n",
      "æ½®æµï¼šæ‹¥æœ‰ä¸“ä¸šçš„éŸ©å›½è®¾è®¡å¸ˆå›¢é˜Ÿï¼Œè§£ææœ€æ–°çš„éŸ©æµè¶‹åŠ¿ï¼Œä»è€Œç ”å‘å‡ºå…·æœ‰æ—¶å°šã€ä¼˜é›…ã€æ°”è´¨çš„æ¬¾å¼ã€‚\n",
      "å®è¡Œï¼šé€šè¿‡ç½‘ç»œé”€å”®é™ä½è¿è¥æˆæœ¬ï¼ŒçœŸæ­£çš„è®©é”€å”®å•†å’Œæ¶ˆè´¹è€…å¾—åˆ°æœ€å¤§åˆ©ç›Šã€‚\n",
      "å¹´é¾„å®šä½ï¼šæ²å›­é›ªâ€å®šä½äº18-35å²çš„éƒ½å¸‚ç™½é¢†ï¼Œå¥¹ä»¬å‘æ—¶å°šã€è¿½æ±‚æ—¶å°šï¼Œä½†åŒæ—¶åˆå†…æ•›ã€\n",
      "ä¸å¤¸å¼ ï¼Œå¥¹ä»¬æ˜¯æ„Ÿæ€§çš„ä¸”æœ‰ä¸€å®šçš„æ–‡åŒ–ä¿®å…»ï¼Œåœ¨<script> ä¸ç»é—´æµéœ²å‡ºçš„æ˜¯å¥¹ä»¬ä¸ different çš„æ°”è´¨ã€‚\n",
      "è¡£ç€åœºæ‰€ï¼šä¼‘é—²ã€èšä¼šã€è´­ç‰©ã€å·¥ä½œã€‚\n",
      "ä»·æ ¼å®šä½ï¼šæ˜¥ å¤ 159-329 å…ƒä¹‹é—´ï¼Œç§‹ å†¬ 229-459 å…ƒä¹‹é—´ã€‚\n",
      "äº§å“ç»“æ„ï¼šè£™å­ï¼Œè¡£æœï¼Œè£¤å­ï¼ŒåŒ…åŒ…ï¼Œé¥°å“ï¼Œé‹å¸½ç­‰å¤šç³»åˆ—äº§å“ï¼Œä¸­æ–‡å:æ²å›­é›ª,ç±»å‹:å“ç‰Œåç§°,æ‰€å±å…¬å¸:ä¸œèæµ·è‡ªæœé¥°æœ‰é™å…¬å¸</html_brief>\n"
     ]
    }
   ],
   "source": [
    "# Webpage Analysis\n",
    "# Analyze webpage screenshots to understand content, themes, and overall purpose\n",
    "image_path = 'examples/example_webpage.png'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>What is the central theme of the webpage picture?'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <tikz>\\documentclass[tikz,border=2mm]{standalone}\n",
      "\\usetikzlibrary{angles,quotes}\n",
      "\n",
      "\\begin{document}\n",
      "\\begin{tikzpicture}[scale=0.8]\n",
      "\\draw[thick] (0,0) coordinate (A) -- node[below] {$x$} (4,0) coordinate (B) -- node[above] {$y$} (0,2.5) coordinate (C) -- cycle;\n",
      "\\draw pic[\"$60^\\circ$\", draw, angle eccentricity=1.5, angle radius=0.8cm] {angle=B--C--A};\n",
      "\\draw (0,0.2) -- (0.2,0.2) -- (0.2,0);\n",
      "\\node[left] at (0,1.25) {5};\n",
      "\\end{tikzpicture}\n",
      "\\end{document}</tikz>\n"
     ]
    }
   ],
   "source": [
    "# Scientific Diagram Code Generation\n",
    "# Generate TikZ code for recreating scientific diagrams\n",
    "image_path = 'examples/example_diagram.png'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>Please show me the TikZ code for displaying this image.'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <json>{\"å‡ºå‘ç«™\": \"å—äº¬å—ç«™\", \"åˆ°è¾¾ç«™\": \"åŒ—äº¬å—ç«™\", \"åº§ä½ç±»åˆ«\": \"ä¸€ç­‰åº§\", \"ç¥¨ä»·\": \"ï¿¥748.5å…ƒ\", \"è½¦ç¥¨ç¼–ç \": \"Z66N041840\", \"å‡ºå‘æ—¥æœŸ\": \"2017å¹´11æœˆ16æ—¥\", \"è½¦æ¬¡\": \"G40\", \"ä¹˜å®¢å§“å\": \"å˜‰å—\"}</json>\n"
     ]
    }
   ],
   "source": [
    "# Structured Data Extraction\n",
    "# Extract structured information from ticket image\n",
    "image_path = 'examples/example_ticket.jpg'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>Get the text in the image as JSON.'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: <json>{\"title\": \"Most preferred objects of different categories\", \"source\": \"None\", \"x_title\": \"None\", \"y_title\": \"Percent of People\", \"values\": {\"bird\": {\"car\": \"50 kg\", \"weight\": \"40 kg\", \"plain\": \"70 kg\", \"sir\": \"50 kg\"}, \"letter\": {\"car\": \"50 kg\", \"weight\": \"60 kg\", \"plain\": \"30 kg\", \"sir\": \"50 kg\"}}}</json>\n"
     ]
    }
   ],
   "source": [
    "# Extract textual content from chart image\n",
    "image_path = 'examples/example_chart.png'\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "question = '<image>Use JSON to extract textual content from the image.'\n",
    "answer = model.chat(tokenizer, pixel_values, question, generation_config, skip_special_tokens=False)\n",
    "print('Answer:', answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
